{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/app')\n",
    "\n",
    "\n",
    "import timecorr as tc\n",
    "from timecorr.helpers import isfc, wisfc, mean_combine, corrmean_combine\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), '..', '..','data')  # Set 'data' as the base directory\n",
    "\n",
    "\n",
    "#Load datasets in to working memory.\n",
    "pieman_conds = ['intact', 'paragraph', 'word', 'rest']\n",
    "pieman_100 = loadmat(os.path.join(data_dir, 'pieman_ica100.mat'))\n",
    "pieman_700 = loadmat(os.path.join(data_dir, 'pieman_data.mat'))\n",
    "\n",
    "len(pieman_700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intact\n",
      "paragraph\n",
      "word\n",
      "rest\n"
     ]
    }
   ],
   "source": [
    "# Remove bad data from the datafiles, save as numpy array\n",
    "pieman_100_data_conditioned = []\n",
    "pieman_700_data_conditioned = []\n",
    "conds_100 = []\n",
    "conds_700 = []\n",
    "\n",
    "def subjects_from_cell(A):\n",
    "    # A: ndarray(dtype=object, shape=(N,)) where each elem is (T, F)\n",
    "    return [np.asarray(x).squeeze() for x in A.ravel()]\n",
    "\n",
    "for c in pieman_conds:\n",
    "    print(c)\n",
    "\n",
    "    # --- 700 set: cell array of subjects, each (T, 700) ---\n",
    "    subs_700 = subjects_from_cell(pieman_700[c])\n",
    "    if c == 'paragraph' and len(subs_700) > 3:\n",
    "        # drop subject index 3 (0-based) for paragraph\n",
    "        subs_700 = [s for i, s in enumerate(subs_700) if i != 3]\n",
    "\n",
    "    # --- 100 set: may be cell or numeric; normalize to per-subject arrays ---\n",
    "    A100 = pieman_100[c]\n",
    "    if isinstance(A100, np.ndarray) and A100.dtype == object:\n",
    "        subs_100 = subjects_from_cell(A100)      # list of (T, 100)\n",
    "    else:\n",
    "        A100 = np.asarray(A100)\n",
    "        # Common layout: time x subjects (T x N)\n",
    "        if A100.ndim == 2:\n",
    "            subs_100 = [A100[:, i].squeeze() for i in range(A100.shape[1])]\n",
    "        elif A100.ndim == 3:\n",
    "            subs_100 = [A100[..., i].squeeze() for i in range(A100.shape[-1])]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected 100-set shape for {c}: {A100.shape}\")\n",
    "\n",
    "    if c == 'paragraph' and len(subs_100) > 0:\n",
    "        # drop subject index 0 (0-based) for paragraph\n",
    "        subs_100 = [s for i, s in enumerate(subs_100) if i != 0]\n",
    "\n",
    "    # accumulate\n",
    "    pieman_700_data_conditioned.extend(subs_700)\n",
    "    pieman_100_data_conditioned.extend(subs_100)\n",
    "    conds_700.extend([c] * len(subs_700))\n",
    "    conds_100.extend([c] * len(subs_100))\n",
    "\n",
    "# Convert AFTER the loop (preserve per-subject arrays -> object dtype)\n",
    "pieman_700_data_conditioned = np.array(pieman_700_data_conditioned, dtype=object)  # each (T, 700)\n",
    "pieman_100_data_conditioned = np.array(pieman_100_data_conditioned, dtype=object)  # each (T, 100)\n",
    "conds_700 = np.array(conds_700)\n",
    "conds_100 = np.array(conds_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 files to /app/Scripts/Old/../../data/initial_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "out_dir = Path(os.getcwd(), '..', '..', 'data') / \"initial_data\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for cond in pieman_conds: \n",
    "    # 100-node subjects for this condition\n",
    "    idx_100 = np.where(conds_100 == cond)[0]\n",
    "    subs_100 = pieman_100_data_conditioned[idx_100]\n",
    "    np.save(out_dir / f\"pieman_data_100_{cond}.npy\", subs_100, allow_pickle=True)\n",
    "\n",
    "    # 700-node subjects for this condition\n",
    "    idx_700 = np.where(conds_700 == cond)[0]\n",
    "    subs_700 = pieman_700_data_conditioned[idx_700]\n",
    "    np.save(out_dir / f\"pieman_data_700_{cond}.npy\", subs_700, allow_pickle=True)\n",
    "\n",
    "print(\"Saved 8 files to\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/Scripts/Old\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pieman_100_intact.npy: 36 subjects, shapes {(300, 100)}\n",
      "   max|sub0-sub1| = 0.2657\n",
      "pieman_100_paragraph.npy: 17 subjects, shapes {(272, 100)}\n",
      "   max|sub0-sub1| = 0.3116\n",
      "pieman_100_word.npy: 36 subjects, shapes {(300, 100)}\n",
      "   max|sub0-sub1| = 0.1860\n",
      "pieman_100_rest.npy: 36 subjects, shapes {(400, 100)}\n",
      "   max|sub0-sub1| = 0.3673\n",
      "pieman_700_intact.npy: 36 subjects, shapes {(300, 700)}\n",
      "   max|sub0-sub1| = 8.9610\n",
      "pieman_700_paragraph.npy: 17 subjects, shapes {(272, 700)}\n",
      "   max|sub0-sub1| = 10.0279\n",
      "pieman_700_word.npy: 36 subjects, shapes {(300, 700)}\n",
      "   max|sub0-sub1| = 11.0626\n",
      "pieman_700_rest.npy: 36 subjects, shapes {(400, 700)}\n",
      "   max|sub0-sub1| = 10.7606\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/app/data/initial_data\")\n",
    "\n",
    "# loop over all 8 expected files\n",
    "for node in [100, 700]:\n",
    "    for cond in [\"intact\", \"paragraph\", \"word\", \"rest\"]:\n",
    "        fname = data_dir / f\"pieman_{node}_{cond}.npy\"\n",
    "        arr = np.load(fname, allow_pickle=True)\n",
    "        n_subs = len(arr)\n",
    "        shapes = {s.shape for s in arr}\n",
    "        print(f\"{fname.name}: {n_subs} subjects, shapes {shapes}\")\n",
    "\n",
    "        # sanity: compare first two subjects if >1\n",
    "        if n_subs > 1:\n",
    "            diff = np.max(np.abs(arr[0] - arr[1]))\n",
    "            print(f\"   max|sub0-sub1| = {diff:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
